#+title: TD SIMD
#+author: Nicolas Bouton
#+date: 2020

* Information
** Makefile
*** Compile

    Run the command below to compile the program with *gcc* and *clang*
    with different optimization.

    #+begin_src bash
    $ make
    #+end_src

*** Clean

    You can also clean the *binary* and *~* file with :

    #+begin_src bash
    $ make clean
    #+end_src
    
** Script
*** Install script

    Desassemble *binary* file, and move *assembler* file. This script
    is called by *make* command.

    Usage :

    #+begin_src bash
    $ ./install.sh
    #+end_src

    Also called by :

    #+begin_src bash
    $ make asm
    #+end_src

** Provide file

   There are 3 given files on the folders : *gcc_ver.txt*,
   *clang_ver.txt* and *cpuinfo.txt*.

* Answer
** Introduction

  Here I will compare *two compiler* by optimization flags.
  
  - gcc
  - clang
    
** Code

   In my c code, I let user to choice one size of the matrix to see
   the dynamic compilation effect and I fix a size in the code to see
   the static compilation effect.

** Base
*** gcc
**** Scalar

     #+begin_src asm
     00000000000011a4 <dotprod>:
     11a4:	48 85 d2             	test   %rdx,%rdx
     11a7:	74 25                	je     11ce <dotprod+0x2a>
     11a9:	b8 00 00 00 00       	mov    $0x0,%eax
     11ae:	66 0f ef c9          	pxor   %xmm1,%xmm1
     11b2:	f2 0f 10 04 c7       	movsd  (%rdi,%rax,8),%xmm0
     11b7:	f2 0f 59 04 c6       	mulsd  (%rsi,%rax,8),%xmm0
     11bc:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     11c0:	48 83 c0 01          	add    $0x1,%rax
     11c4:	48 39 c2             	cmp    %rax,%rdx
     11c7:	75 e9                	jne    11b2 <dotprod+0xe>
     11c9:	66 0f 28 c1          	movapd %xmm1,%xmm0
     11cd:	c3                   	retq   
     11ce:	66 0f ef c9          	pxor   %xmm1,%xmm1
     11d2:	eb f5                	jmp    11c9 <dotprod+0x25>
     #+end_src

     We can see that on the loop which begin at *11b2* and finish at
     *11c7*, *gcc* doesn't use vector instruction (because it is *sd*
     = scalar double), even if it uses *xmm* register wich are 128
     bits. Because we need to have *pd* instructions *+* vector
     registers to have vector instructions.

**** Vector
***** 2 double

      *Case - size is divisible by 2:*

      #+begin_src asm
      11e9:	f2 0f 10 04 c7       	movsd  (%rdi,%rax,8),%xmm0
      11ee:	f2 0f 59 04 c6       	mulsd  (%rsi,%rax,8),%xmm0
      11f3:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
      11f7:	f2 0f 10 44 c7 08    	movsd  0x8(%rdi,%rax,8),%xmm0
      11fd:	f2 0f 59 44 c6 08    	mulsd  0x8(%rsi,%rax,8),%xmm0
      1203:	f2 0f 58 d0          	addsd  %xmm0,%xmm2
      1207:	48 83 c0 02          	add    $0x2,%rax
      120b:	48 39 c2             	cmp    %rax,%rdx
      120e:	77 d9                	ja     11e9 <dotprod_2x+0x15>
      #+end_src

      We can see that *gcc* uses also *sd* instructions. It didn't vectorized.

      *Case - size is not divisible by 2:*

      It is the same code but at the end of the boucle we do one more
      multiplication. Therefore *gcc* uses also *sd* instructions and
      it didn't vectorized too.

***** 4 double

      *Case - size is divisible by 4:*

      #+begin_src asm
      12b6:	f2 0f 10 00          	movsd  (%rax),%xmm0
      12ba:	f2 0f 59 02          	mulsd  (%rdx),%xmm0
      12be:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
      12c2:	f2 0f 10 40 08       	movsd  0x8(%rax),%xmm0
      12c7:	f2 0f 59 42 08       	mulsd  0x8(%rdx),%xmm0
      12cc:	f2 0f 58 e0          	addsd  %xmm0,%xmm4
      12d0:	f2 0f 10 40 10       	movsd  0x10(%rax),%xmm0
      12d5:	f2 0f 59 42 10       	mulsd  0x10(%rdx),%xmm0
      12da:	f2 0f 58 d8          	addsd  %xmm0,%xmm3
      12de:	f2 0f 10 40 18       	movsd  0x18(%rax),%xmm0
      12e3:	f2 0f 59 42 18       	mulsd  0x18(%rdx),%xmm0
      12e8:	f2 0f 58 d0          	addsd  %xmm0,%xmm2
      12ec:	48 83 c0 20          	add    $0x20,%rax
      12f0:	48 83 c2 20          	add    $0x20,%rdx
      12f4:	48 39 c8             	cmp    %rcx,%rax
      12f7:	75 bd                	jne    12b6 <dotprod_4x+0x3d>
      #+end_src

      *gcc* uses *sd* instructions and make 4 *multiplications* and
      *additions* by turn of loop. It didn't vectorized.

      *Case - size is not divisible by 4:*

      Same code as above plus :

      #+begin_src asm
      1319:	f2 0f 10 04 c7       	movsd  (%rdi,%rax,8),%xmm0
      131e:	f2 41 0f 59 04 c0    	mulsd  (%r8,%rax,8),%xmm0
      1324:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
      1328:	48 83 c0 01          	add    $0x1,%rax
      132c:	48 39 c6             	cmp    %rax,%rsi
      132f:	75 e8                	jne    1319 <dotprod_4x+0xa0>
      #+end_src

      *gcc* uses *sd* instructions and make 4 *multiplications* and
      *additions* by turn of loop. It didn't vectorized too.

***** 8 double

      *Case - size is divisible by 8:*

      #+begin_src asm
      139a:	f2 0f 10 08          	movsd  (%rax),%xmm1
      139e:	f2 0f 59 0a          	mulsd  (%rdx),%xmm1
      13a2:	f2 0f 58 c1          	addsd  %xmm1,%xmm0
      13a6:	f2 0f 10 48 08       	movsd  0x8(%rax),%xmm1
      13ab:	f2 0f 59 4a 08       	mulsd  0x8(%rdx),%xmm1
      13b0:	f2 0f 58 f9          	addsd  %xmm1,%xmm7
      13b4:	f2 0f 10 48 10       	movsd  0x10(%rax),%xmm1
      13b9:	f2 0f 59 4a 10       	mulsd  0x10(%rdx),%xmm1
      13be:	f2 0f 58 f1          	addsd  %xmm1,%xmm6
      13c2:	f2 0f 10 48 18       	movsd  0x18(%rax),%xmm1
      13c7:	f2 0f 59 4a 18       	mulsd  0x18(%rdx),%xmm1
      13cc:	f2 0f 58 e9          	addsd  %xmm1,%xmm5
      13d0:	f2 0f 10 48 20       	movsd  0x20(%rax),%xmm1
      13d5:	f2 0f 59 4a 20       	mulsd  0x20(%rdx),%xmm1
      13da:	f2 0f 58 e1          	addsd  %xmm1,%xmm4
      13de:	f2 0f 10 48 28       	movsd  0x28(%rax),%xmm1
      13e3:	f2 0f 59 4a 28       	mulsd  0x28(%rdx),%xmm1
      13e8:	f2 0f 58 d9          	addsd  %xmm1,%xmm3
      13ec:	f2 0f 10 48 30       	movsd  0x30(%rax),%xmm1
      13f1:	f2 0f 59 4a 30       	mulsd  0x30(%rdx),%xmm1
      13f6:	f2 0f 58 d1          	addsd  %xmm1,%xmm2
      13fa:	f2 0f 10 48 38       	movsd  0x38(%rax),%xmm1
      13ff:	f2 0f 59 4a 38       	mulsd  0x38(%rdx),%xmm1
      1404:	f2 44 0f 58 c1       	addsd  %xmm1,%xmm8
      1409:	48 83 c0 40          	add    $0x40,%rax
      140d:	48 83 c2 40          	add    $0x40,%rdx
      1411:	48 39 f0             	cmp    %rsi,%rax
      1414:	75 84                	jne    139a <dotprod_8x+0x55>
      #+end_src

      *gcc* uses *sd* instructions and make 8 *multiplications* and
      *additions* by turn of loop. It didn't vectorized.

      *Case - size is not divisible by 8:*

      Same code as above plus :

      #+begin_src asm
      1443:	f2 0f 10 0c c7       	movsd  (%rdi,%rax,8),%xmm1
      1448:	f2 41 0f 59 0c c0    	mulsd  (%r8,%rax,8),%xmm1
      144e:	f2 0f 58 c1          	addsd  %xmm1,%xmm0
      1452:	48 83 c0 01          	add    $0x1,%rax
      1456:	48 39 c1             	cmp    %rax,%rcx
      1459:	75 e8                	jne    1443 <dotprod_8x+0xfe>
      #+end_src

      *gcc* uses *sd* instructions and make 8 *multiplications* and
      *additions* by turn of loop. It didn't vectorized too.

***** 16 double

      *Case - size is divisible by 16:*

      #+begin_src asm
      1501:	f2 0f 10 18          	movsd  (%rax),%xmm3
      1505:	f2 0f 59 1a          	mulsd  (%rdx),%xmm3
      1509:	f2 0f 58 c3          	addsd  %xmm3,%xmm0
      150d:	f2 0f 10 58 08       	movsd  0x8(%rax),%xmm3
      1512:	f2 0f 59 5a 08       	mulsd  0x8(%rdx),%xmm3
      1517:	f2 0f 58 d3          	addsd  %xmm3,%xmm2
      151b:	f2 0f 10 58 10       	movsd  0x10(%rax),%xmm3
      1520:	f2 0f 59 5a 10       	mulsd  0x10(%rdx),%xmm3
      1525:	f2 44 0f 58 fb       	addsd  %xmm3,%xmm15
      152a:	f2 0f 10 58 18       	movsd  0x18(%rax),%xmm3
      152f:	f2 0f 59 5a 18       	mulsd  0x18(%rdx),%xmm3
      1534:	f2 44 0f 58 f3       	addsd  %xmm3,%xmm14
      1539:	f2 0f 10 58 20       	movsd  0x20(%rax),%xmm3
      153e:	f2 0f 59 5a 20       	mulsd  0x20(%rdx),%xmm3
      1543:	f2 44 0f 58 eb       	addsd  %xmm3,%xmm13
      1548:	f2 0f 10 58 28       	movsd  0x28(%rax),%xmm3
      154d:	f2 0f 59 5a 28       	mulsd  0x28(%rdx),%xmm3
      1552:	f2 0f 58 cb          	addsd  %xmm3,%xmm1
      1556:	f2 0f 10 58 30       	movsd  0x30(%rax),%xmm3
      155b:	f2 0f 59 5a 30       	mulsd  0x30(%rdx),%xmm3
      1560:	f2 44 0f 58 e3       	addsd  %xmm3,%xmm12
      1565:	f2 0f 10 58 38       	movsd  0x38(%rax),%xmm3
      156a:	f2 0f 59 5a 38       	mulsd  0x38(%rdx),%xmm3
      156f:	f2 44 0f 58 db       	addsd  %xmm3,%xmm11
      1574:	f2 0f 10 58 40       	movsd  0x40(%rax),%xmm3
      1579:	f2 0f 59 5a 40       	mulsd  0x40(%rdx),%xmm3
      157e:	f2 44 0f 58 d3       	addsd  %xmm3,%xmm10
      1583:	f2 0f 10 58 48       	movsd  0x48(%rax),%xmm3
      1588:	f2 0f 59 5a 48       	mulsd  0x48(%rdx),%xmm3
      158d:	f2 44 0f 58 cb       	addsd  %xmm3,%xmm9
      1592:	f2 0f 10 58 50       	movsd  0x50(%rax),%xmm3
      1597:	f2 0f 59 5a 50       	mulsd  0x50(%rdx),%xmm3
      159c:	f2 44 0f 58 c3       	addsd  %xmm3,%xmm8
      15a1:	f2 0f 10 58 58       	movsd  0x58(%rax),%xmm3
      15a6:	f2 0f 59 5a 58       	mulsd  0x58(%rdx),%xmm3
      15ab:	f2 0f 58 fb          	addsd  %xmm3,%xmm7
      15af:	f2 0f 10 58 60       	movsd  0x60(%rax),%xmm3
      15b4:	f2 0f 59 5a 60       	mulsd  0x60(%rdx),%xmm3
      15b9:	f2 0f 58 f3          	addsd  %xmm3,%xmm6
      15bd:	f2 0f 10 58 68       	movsd  0x68(%rax),%xmm3
      15c2:	f2 0f 59 5a 68       	mulsd  0x68(%rdx),%xmm3
      15c7:	f2 0f 58 eb          	addsd  %xmm3,%xmm5
      15cb:	f2 0f 10 58 70       	movsd  0x70(%rax),%xmm3
      15d0:	f2 0f 59 5a 70       	mulsd  0x70(%rdx),%xmm3
      15d5:	f2 0f 58 5c 24 f8    	addsd  -0x8(%rsp),%xmm3
      15db:	f2 0f 11 5c 24 f8    	movsd  %xmm3,-0x8(%rsp)
      15e1:	f2 0f 10 58 78       	movsd  0x78(%rax),%xmm3
      15e6:	f2 0f 59 5a 78       	mulsd  0x78(%rdx),%xmm3
      15eb:	f2 0f 58 e3          	addsd  %xmm3,%xmm4
      15ef:	48 83 e8 80          	sub    $0xffffffffffffff80,%rax
      15f3:	48 83 ea 80          	sub    $0xffffffffffffff80,%rdx
      15f7:	4c 39 c8             	cmp    %r9,%rax
      15fa:	0f 85 01 ff ff ff    	jne    1501 <dotprod_16x+0x7a>
      #+end_src

      *gcc* uses *sd* instructions and make 16 *multiplications* and
      *additions* by turn of loop. It didn't vectorized.

      *Case - size is not divisible by 16:*

      Same code as above plus :

      #+begin_src asm
      165a:	f2 0f 10 1c c7       	movsd  (%rdi,%rax,8),%xmm3
      165f:	f2 41 0f 59 1c c0    	mulsd  (%r8,%rax,8),%xmm3
      1665:	f2 0f 58 c3          	addsd  %xmm3,%xmm0
      1669:	48 83 c0 01          	add    $0x1,%rax
      166d:	48 39 c6             	cmp    %rax,%rsi
      1670:	75 e8                	jne    165a <dotprod_16x+0x1d3>
      #+end_src

      *gcc* uses *sd* instructions and make 16 *multiplications* and
      *additions* by turn of loop. It didn't vectorized too.

*** clang
    
    *clang* does the same as *gcc*. It don't use *pd* instructions and
    make as many of operations by turn of loop that the code is
    supposed to do. It didn't vectorized.

*** static vs dynamic
    
    No differennce. The main function calls *dotprod* fucntions.

*** ccl

    Vectorized instruction by functions and compiler :

    | compiler \ functions | baseline | vector_2x | vector_4x | vector_8x | vector_16x |
    |----------------------+----------+-----------+-----------+-----------+------------|
    | gcc                  | no       | no        | no        | no        | no         |
    | clang                | no       | no        | no        | no        | no         |

** Light
*** gcc
**** Scalar

     #+begin_src asm
     00000000000014b0 <dotprod>:
     14b0:	48 85 d2             	test   %rdx,%rdx
     14b3:	74 2b                	je     14e0 <dotprod+0x30>
     14b5:	31 c0                	xor    %eax,%eax
     14b7:	66 0f ef c9          	pxor   %xmm1,%xmm1
     14bb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
     14c0:	f2 0f 10 04 c7       	movsd  (%rdi,%rax,8),%xmm0
     14c5:	f2 0f 59 04 c6       	mulsd  (%rsi,%rax,8),%xmm0
     14ca:	48 83 c0 01          	add    $0x1,%rax
     14ce:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     14d2:	48 39 c2             	cmp    %rax,%rdx
     14d5:	75 e9                	jne    14c0 <dotprod+0x10>
     14d7:	66 0f 28 c1          	movapd %xmm1,%xmm0
     14db:	c3                   	retq   
     14dc:	0f 1f 40 00          	nopl   0x0(%rax)
     14e0:	66 0f ef c9          	pxor   %xmm1,%xmm1
     14e4:	66 0f 28 c1          	movapd %xmm1,%xmm0
     14e8:	c3                   	retq   
     14e9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
     #+end_src

     *gcc* doesn't use vector instruction(*pd*). It uses scalar
     instruction(*sd*). And it make 1 *multiplications* and
     *additions* by turn of loop(begin at *14c0* and finish at *14d5*)
     like the *c code*.

**** Vector

     For vector of 2 double :

     #+begin_src asm
     1510:	f2 0f 10 04 c7       	movsd  (%rdi,%rax,8),%xmm0
     1515:	f2 0f 59 04 c6       	mulsd  (%rsi,%rax,8),%xmm0
     151a:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     151e:	f2 0f 10 44 c7 08    	movsd  0x8(%rdi,%rax,8),%xmm0
     1524:	f2 0f 59 44 c6 08    	mulsd  0x8(%rsi,%rax,8),%xmm0
     152a:	48 83 c0 02          	add    $0x2,%rax
     152e:	f2 0f 58 d0          	addsd  %xmm0,%xmm2
     1532:	48 39 c2             	cmp    %rax,%rdx
     1535:	77 d9                	ja     1510 <dotprod_2x+0x20>
     #+end_src

    *gcc* uses *sd* instructions and make as many operations than *c
    code*. It is also the same for others vectors functions so I will
    not show them.

*** clang
**** Scalar

    Same as *gcc*, uses *sd* instructions.

**** Vector
***** 2 double

      For the vectorized loop :

      #+begin_src asm
      1270:	66 0f 10 04 c7       	movupd (%rdi,%rax,8),%xmm0
      1275:	66 0f 10 14 c6       	movupd (%rsi,%rax,8),%xmm2
      127a:	66 0f 59 d0          	mulpd  %xmm0,%xmm2
      127e:	66 0f 58 ca          	addpd  %xmm2,%xmm1
      1282:	48 83 c0 02          	add    $0x2,%rax
      1286:	48 39 d0             	cmp    %rdx,%rax
      1289:	72 e5                	jb     1270 <dotprod_2x+0x10>
      #+end_src

     We can see that *clang* vecorized instructions, because we have *pd*
     instructions like *movupd*, *mulpd* and *addpd*. But it keep 2
     *multiplication* and *addition* in one turn of loop.

     For the case that we have odd numbers we have the same code plus
     one scalar instruction for the last one.

***** 4 double

      #+begin_src asm
      1310:	f2 0f 10 14 c7       	movsd  (%rdi,%rax,8),%xmm2
      1315:	f2 0f 10 5c c7 08    	movsd  0x8(%rdi,%rax,8),%xmm3
      131b:	66 0f 16 54 c7 10    	movhpd 0x10(%rdi,%rax,8),%xmm2
      1321:	f2 0f 10 24 c6       	movsd  (%rsi,%rax,8),%xmm4
      1326:	f2 0f 10 6c c6 08    	movsd  0x8(%rsi,%rax,8),%xmm5
      132c:	66 0f 16 64 c6 10    	movhpd 0x10(%rsi,%rax,8),%xmm4
      1332:	66 0f 59 e2          	mulpd  %xmm2,%xmm4
      1336:	66 0f 58 cc          	addpd  %xmm4,%xmm1
      133a:	66 0f 16 5c c7 18    	movhpd 0x18(%rdi,%rax,8),%xmm3
      1340:	66 0f 16 6c c6 18    	movhpd 0x18(%rsi,%rax,8),%xmm5
      1346:	66 0f 59 eb          	mulpd  %xmm3,%xmm5
      134a:	66 0f 58 c5          	addpd  %xmm5,%xmm0
      134e:	48 83 c0 04          	add    $0x4,%rax
      1352:	48 39 d0             	cmp    %rdx,%rax
      1355:	72 b9                	jb     1310 <dotprod_4x+0x20>
      #+end_src

      Here *clang* vectorized too, but not *move* instructions. We
      have 4 *movsd* by turn of loop. And it vectorized with register
      vector of 2 double, 128 bits size. Therefore it vectorized to
      about half. It does the same number of *operation* by turn of
      loop, that is 4 *multiplications* and *additions*.

***** Other vectorire function

      Same as vector of 4 double.

**** main

    I see that main call *dotprod_8x* and *dotprod_16x* for dynamic.

    #+begin_src asm
    1a8f:	66 0f 29 7c 24 20    	movapd %xmm7,0x20(%rsp)
    1a95:	4c 89 f7             	mov    %r14,%rdi
    1a98:	48 89 de             	mov    %rbx,%rsi
    1a9b:	4c 89 fa             	mov    %r15,%rdx
    1a9e:	e8 1d f9 ff ff       	callq  13c0 <dotprod_8x>
    1aa3:	f2 0f 11 44 24 18    	movsd  %xmm0,0x18(%rsp)
    1aa9:	4c 89 f7             	mov    %r14,%rdi
    1aac:	48 89 de             	mov    %rbx,%rsi
    1aaf:	4c 89 fa             	mov    %r15,%rdx
    1ab2:	e8 69 fa ff ff       	callq  1520 <dotprod_16x>
    #+end_src

    And *dotprod_16x* for static.

    #+begin_src asm
    1b76:	4c 89 60 20          	mov    %r12,0x20(%rax)
    1b7a:	ba 05 00 00 00       	mov    $0x5,%edx
    1b7f:	48 89 df             	mov    %rbx,%rdi
    1b82:	48 89 c6             	mov    %rax,%rsi
    1b85:	e8 96 f9 ff ff       	callq  1520 <dotprod_16x>
    #+end_src

    And I don't understand why the other are disapear. I found their
    name on *debug function*.

*** static vs dynamic

    Not difference.

*** ccl

    Vectorized instruction by functions and compiler :

    | compiler \ functions | baseline | vector_2x | vector_4x  | vector_8x  | vector_16x |
    |----------------------+----------+-----------+------------+------------+------------|
    | gcc                  | no       | no        | no         | no         | no         |
    | clang                | no       | yes       | yes (half) | yes (half) | yes (half) |

** Optimized
*** gcc
**** Scalar
     
     #+begin_src asm
     1570:	66 0f 10 04 07       	movupd (%rdi,%rax,1),%xmm0
     1575:	66 0f 10 1c 06       	movupd (%rsi,%rax,1),%xmm3
     157a:	48 83 c0 10          	add    $0x10,%rax
     157e:	66 0f 59 c3          	mulpd  %xmm3,%xmm0
     1582:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     1586:	66 0f 15 c0          	unpckhpd %xmm0,%xmm0
     158a:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     158e:	48 39 c1             	cmp    %rax,%rcx
     1591:	75 dd                	jne    1570 <dotprod+0x20>
     #+end_src

     I think *gcc* vectorized the multiplication and make 2 operations
     by turn of loop because we have 2 *additions* wich corresponding
     at the addition with *d* in *c code*. And the *unpckhpd* be used
     for recup the second operand for the 2nd addition, bacause
     *additions* are not vectorized here.

**** Vector
     
     *gcc* also make the same for vector functions.

     For exemple (vector of 2 double) :

     #+begin_src asm
     1610:	66 0f 10 1c 07       	movupd (%rdi,%rax,1),%xmm3
     1615:	66 0f 10 04 06       	movupd (%rsi,%rax,1),%xmm0
     161a:	66 0f 16 5c 07 10    	movhpd 0x10(%rdi,%rax,1),%xmm3
     1620:	66 0f 16 44 06 10    	movhpd 0x10(%rsi,%rax,1),%xmm0
     1626:	66 0f 59 d8          	mulpd  %xmm0,%xmm3
     162a:	66 0f 10 44 07 10    	movupd 0x10(%rdi,%rax,1),%xmm0
     1630:	66 0f 12 44 07 08    	movlpd 0x8(%rdi,%rax,1),%xmm0
     1636:	f2 0f 58 d3          	addsd  %xmm3,%xmm2
     163a:	66 0f 15 db          	unpckhpd %xmm3,%xmm3
     163e:	f2 0f 58 d3          	addsd  %xmm3,%xmm2
     1642:	66 0f 10 5c 06 10    	movupd 0x10(%rsi,%rax,1),%xmm3
     1648:	66 0f 12 5c 06 08    	movlpd 0x8(%rsi,%rax,1),%xmm3
     164e:	48 83 c0 20          	add    $0x20,%rax
     1652:	66 0f 59 c3          	mulpd  %xmm3,%xmm0
     1656:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     165a:	66 0f 15 c0          	unpckhpd %xmm0,%xmm0
     165e:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     1662:	48 39 d0             	cmp    %rdx,%rax
     1665:	75 a9                	jne    1610 <dotprod_2x+0x40>
     #+end_src
     
     Here, it vectorized *multiplications* but not *additions*. It is
     the same for others vector functions.

*** clang
**** Scalar

     #+begin_src asm
     11e0:	f2 0f 10 0c cf       	movsd  (%rdi,%rcx,8),%xmm1
     11e5:	f2 0f 10 54 cf 08    	movsd  0x8(%rdi,%rcx,8),%xmm2
     11eb:	f2 0f 59 0c ce       	mulsd  (%rsi,%rcx,8),%xmm1
     11f0:	f2 0f 59 54 ce 08    	mulsd  0x8(%rsi,%rcx,8),%xmm2
     11f6:	f2 0f 58 c8          	addsd  %xmm0,%xmm1
     11fa:	f2 0f 10 5c cf 10    	movsd  0x10(%rdi,%rcx,8),%xmm3
     1200:	f2 0f 59 5c ce 10    	mulsd  0x10(%rsi,%rcx,8),%xmm3
     1206:	f2 0f 58 d1          	addsd  %xmm1,%xmm2
     120a:	f2 0f 10 44 cf 18    	movsd  0x18(%rdi,%rcx,8),%xmm0
     1210:	f2 0f 59 44 ce 18    	mulsd  0x18(%rsi,%rcx,8),%xmm0
     1216:	f2 0f 58 da          	addsd  %xmm2,%xmm3
     121a:	f2 0f 58 c3          	addsd  %xmm3,%xmm0
     121e:	48 83 c1 04          	add    $0x4,%rcx
     1222:	48 39 ca             	cmp    %rcx,%rdx
     1225:	75 b9                	jne    11e0 <dotprod+0x30>
     #+end_src

     *clang* doesn't vectorized instructions. It uses *sd*
     instructions with *multiplications* instruction adress. But it
     *unroll loop* and make 4 times the operatons on *c code* by turn.

**** Vector
***** 2 double

     #+begin_src asm
     1270:	66 0f 10 04 c7       	movupd (%rdi,%rax,8),%xmm0
     1275:	66 0f 10 14 c6       	movupd (%rsi,%rax,8),%xmm2
     127a:	66 0f 59 d0          	mulpd  %xmm0,%xmm2
     127e:	66 0f 58 ca          	addpd  %xmm2,%xmm1
     1282:	48 83 c0 02          	add    $0x2,%rax
     1286:	48 39 d0             	cmp    %rdx,%rax
     1289:	72 e5                	jb     1270 <dotprod_2x+0x10>
     #+end_src

     *clang* vectorized the loop(*pd* instructions) and do exactly the
     same numbers of operations than *c code*.

***** 4 double

     #+begin_src asm
     1310:	f2 0f 10 14 c7       	movsd  (%rdi,%rax,8),%xmm2
     1315:	f2 0f 10 5c c7 08    	movsd  0x8(%rdi,%rax,8),%xmm3
     131b:	66 0f 16 54 c7 10    	movhpd 0x10(%rdi,%rax,8),%xmm2
     1321:	f2 0f 10 24 c6       	movsd  (%rsi,%rax,8),%xmm4
     1326:	f2 0f 10 6c c6 08    	movsd  0x8(%rsi,%rax,8),%xmm5
     132c:	66 0f 16 64 c6 10    	movhpd 0x10(%rsi,%rax,8),%xmm4
     1332:	66 0f 59 e2          	mulpd  %xmm2,%xmm4
     1336:	66 0f 58 cc          	addpd  %xmm4,%xmm1
     133a:	66 0f 16 5c c7 18    	movhpd 0x18(%rdi,%rax,8),%xmm3
     1340:	66 0f 16 6c c6 18    	movhpd 0x18(%rsi,%rax,8),%xmm5
     1346:	66 0f 59 eb          	mulpd  %xmm3,%xmm5
     134a:	66 0f 58 c5          	addpd  %xmm5,%xmm0
     134e:	48 83 c0 04          	add    $0x4,%rax
     1352:	48 39 d0             	cmp    %rdx,%rax
     1355:	72 b9                	jb     1310 <dotprod_4x+0x20>
     #+end_src

     *clang* vectorized *multiplications* and *additions* but not
     *move* instructions. And it respect the number of operations by
     turn of loop of *c code*.

***** 8 and 16 double

      Same as 4 double.

*** static vs dynamic

    The call on main of the function *dotprod_2x* (for vector of 2)
    for static array disapeared on main functions in assmebler for
    *gcc*.

    For *clang* it is almost all call which disapeared.

*** ccl

    Vectorized instruction by functions and compiler :

    | compiler \ functions | baseline   | vector_2x  | vector_4x  | vector_8x  | vector_16x |
    |----------------------+------------+------------+------------+------------+------------|
    | gcc                  | yes (half) | yes (half) | yes (half) | yes (half) | yes (half) |
    | clang                | no         | yes        | yes (half) | yes (half) | yes (half) |

** High
*** gcc
**** Scalar

     #+begin_src asm
     15a0:	66 0f 10 04 07       	movupd (%rdi,%rax,1),%xmm0
     15a5:	66 0f 10 1c 06       	movupd (%rsi,%rax,1),%xmm3
     15aa:	48 83 c0 10          	add    $0x10,%rax
     15ae:	66 0f 59 c3          	mulpd  %xmm3,%xmm0
     15b2:	66 0f 58 d0          	addpd  %xmm0,%xmm2
     15b6:	48 39 c1             	cmp    %rax,%rcx
     15b9:	75 e5                	jne    15a0 <dotprod+0x20>
     #+end_src

     *gcc* finnaly, decided to uses instructions, but it is like
     scalar instruction because it doesn't uses 2 double on the
     register. And it keep one *multiplication* and *addition* by turn
     of loop.

**** Vector
***** 2 double

     #+begin_src asm
     1638:	66 0f 10 04 06       	movupd (%rsi,%rax,1),%xmm0
     163d:	66 0f 10 24 07       	movupd (%rdi,%rax,1),%xmm4
     1642:	48 83 c1 01          	add    $0x1,%rcx
     1646:	48 83 c0 10          	add    $0x10,%rax
     164a:	66 0f 59 c4          	mulpd  %xmm4,%xmm0
     164e:	66 0f 58 c8          	addpd  %xmm0,%xmm1
     1652:	48 39 d1             	cmp    %rdx,%rcx
     1655:	72 e1                	jb     1638 <dotprod_2x+0x28>
     #+end_src

     *gcc* finnaly, decided to vectorize instructions. Because it uses
     *pd* instructions and move the iterator 2 times with 2
     **add*. Therefore it concatenate 2 operations on one instructions.
     And it keep 2 *multiplication* and *addition* by turn of loop.

***** 4 double

     #+begin_src asm
     1710:	66 0f 10 04 06       	movupd (%rsi,%rax,1),%xmm0
     1715:	66 0f 10 34 07       	movupd (%rdi,%rax,1),%xmm6
     171a:	48 83 c2 01          	add    $0x1,%rdx
     171e:	66 0f 10 7c 07 10    	movupd 0x10(%rdi,%rax,1),%xmm7
     1724:	66 0f 59 c6          	mulpd  %xmm6,%xmm0
     1728:	66 0f 58 d0          	addpd  %xmm0,%xmm2
     172c:	66 0f 10 44 06 10    	movupd 0x10(%rsi,%rax,1),%xmm0
     1732:	48 83 c0 20          	add    $0x20,%rax
     1736:	66 0f 59 c7          	mulpd  %xmm7,%xmm0
     173a:	66 0f 58 c8          	addpd  %xmm0,%xmm1
     173e:	48 39 d1             	cmp    %rdx,%rcx
     1741:	77 cd                	ja     1710 <dotprod_4x+0x30>
     #+end_src

     *gcc* uses 2 instructions for 4 *multiplications* and the same
     for *additions*. Therefore it vectorize but it doesn't use 256
     bit register.

***** 8 and 16 double

      Same as 4 double vector functions.

*** clang
**** Scalar

     #+begin_src asm
     1220:	66 0f 10 14 cf       	movupd (%rdi,%rcx,8),%xmm2
     1225:	66 0f 10 5c cf 10    	movupd 0x10(%rdi,%rcx,8),%xmm3
     122b:	66 0f 10 64 cf 20    	movupd 0x20(%rdi,%rcx,8),%xmm4
     1231:	66 0f 10 6c cf 30    	movupd 0x30(%rdi,%rcx,8),%xmm5
     1237:	66 0f 10 34 ce       	movupd (%rsi,%rcx,8),%xmm6
     123c:	66 0f 59 f2          	mulpd  %xmm2,%xmm6
     1240:	66 0f 58 f1          	addpd  %xmm1,%xmm6
     1244:	66 0f 10 54 ce 10    	movupd 0x10(%rsi,%rcx,8),%xmm2
     124a:	66 0f 59 d3          	mulpd  %xmm3,%xmm2
     124e:	66 0f 58 d0          	addpd  %xmm0,%xmm2
     1252:	66 0f 10 4c ce 20    	movupd 0x20(%rsi,%rcx,8),%xmm1
     1258:	66 0f 59 cc          	mulpd  %xmm4,%xmm1
     125c:	66 0f 58 ce          	addpd  %xmm6,%xmm1
     1260:	66 0f 10 44 ce 30    	movupd 0x30(%rsi,%rcx,8),%xmm0
     1266:	66 0f 59 c5          	mulpd  %xmm5,%xmm0
     126a:	66 0f 58 c2          	addpd  %xmm2,%xmm0
     126e:	48 83 c1 08          	add    $0x8,%rcx
     1272:	49 83 c1 02          	add    $0x2,%r9
     1276:	75 a8                	jne    1220 <dotprod+0x50>
     #+end_src

     We have 4 *multiplications* and *additions* instructions, and all
     instructions are *pd*. But I can't prove if it uses 2 double on
     registers. So I suppose it does. Therfore *clang* vectorized the
     loop and make 8 *operations* by turn, that is 8 *multiplications*
     and 8 *additions*.

**** Vector
***** 2 double

     #+begin_src asm
     1300:	66 0f 10 04 c7       	movupd (%rdi,%rax,8),%xmm0
     1305:	66 0f 10 14 c6       	movupd (%rsi,%rax,8),%xmm2
     130a:	66 0f 59 d0          	mulpd  %xmm0,%xmm2
     130e:	66 0f 58 ca          	addpd  %xmm2,%xmm1
     1312:	48 83 c0 02          	add    $0x2,%rax
     1316:	48 39 d0             	cmp    %rdx,%rax
     1319:	72 e5                	jb     1300 <dotprod_2x+0x10>
     #+end_src

     *clang* vectorized. 2 *multiplications* in 1 instructions and 2
     *additions* in 1 instructions.

***** Others vector functions

      Same as *opti*.

*** static vs dynamic

    The call on main of the function *dotprod_2x* (for vector of 2)
    for static array disapeared on main functions in assmebler for
    *gcc*.

    For *clang* it is almost all call which disapeared.

*** ccl

    Vectorized instruction by functions and compiler :

    | compiler \ functions | baseline | vector_2x | vector_4x  | vector_8x  | vector_16x |
    |----------------------+----------+-----------+------------+------------+------------|
    | gcc                  | no       | yes       | yes (half) | yes (half) | yes (half) |
    | clang                | yes      | yes       | yes (half) | yes (half) | yes (half) |

** Kamikaze
*** gcc
**** Scalar

     *gcc* replace the loop in scalar function *dotprod* by a multiple
     of instrucions. Therfore it is not vectorized because they are
     just add.

**** Vector

     *gcc* uses *ymm* registers wich are 256 bits and all instrucions
     are *pd*. Therfore it vectorised.

*** clang
    
    *clang* put all functions on main functions and completely
    vectorize all of them with *ymm* register.

*** ccl

    Vectorized instruction by functions and compiler :

    | compiler \ functions | baseline | vector_2x | vector_4x | vector_8x | vector_16x |
    |----------------------+----------+-----------+-----------+-----------+------------|
    | gcc                  | no       | yes       | yes       | yes       | yes        |
    | clang                | yes      | yes       | yes       | yes       | yes        |

